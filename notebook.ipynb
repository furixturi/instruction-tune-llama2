{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction-tune Llama 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Philipp Schmid https://www.philschmid.de/instruction-tune-llama-2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, I launched a `g5.2xlarge` EC2 instance as Philipp described, Installed miniconda.\n",
    "\n",
    "```bash\n",
    "$ wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "$ sh Miniconda3-latest-Linux-x86_64.sh\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For possible interruptions, keep the log somewhere safe. https://stackoverflow.com/questions/47969937/reconnecting-remote-jupyter-notebook-and-get-current-cell-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/projects/finetune-llama-2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(5000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"nb.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers==4.31.0\" \"datasets==2.13.0\" \"peft==0.4.0\" \"accelerate==0.21.0\" \"bitsandbytes==0.40.2\" \"trl==0.4.7\" \"safetensors>=0.3.1\" --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Databricks Dolly dataset `databricks/databricks-dolly-15k`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the dataset from the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset json (/home/ec2-user/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-7427aa6e57c34282/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the hub\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the dataset. The data is in JSON format with the following schema:\n",
    "\n",
    "```js\n",
    "{\n",
    "    'instruction': 'I am trying to book a flight from Singapore to Sydney, what shall I do if the flight is too expensive?', \n",
    "    'context': '', \n",
    "    'response': 'You will have the option to choose from local Asian low-cost airlines such as Scoot, Jetstar, or AirAsia which would provide cheaper flights options.', \n",
    "    'category': 'general_qa'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 15011\n",
      "{'instruction': 'I am trying to book a flight from Singapore to Sydney, what shall I do if the flight is too expensive?', 'context': '', 'response': 'You will have the option to choose from local Asian low-cost airlines such as Scoot, Jetstar, or AirAsia which would provide cheaper flights options.', 'category': 'general_qa'}\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "print(f'dataset size: {len(dataset)}')\n",
    "print(dataset[randrange(len(dataset))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to convert the data into a collection of tasks described by instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instructions(sample):\n",
    "    return f\"\"\"### Instruction:\n",
    "Use the Input below to create an instruction, which could have been used to generate the Input using an LLM.\n",
    "\n",
    "### Input:\n",
    "{sample['response']}\n",
    "\n",
    "### Response:\n",
    "{sample['instruction']}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `format_instructions` function with a random sample in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Write a paragraph about AI governance.', 'context': '', 'response': 'The AI arms race is heating up, and breakthroughs are happening at an accelerating pace.\\n\\nThe release of ChatGPT by OpenAI represents a profound leap forward in how humans interface with machines, showcasing the startling progress in large language models. Meanwhile generative AI capabilities such as Dall-E, Stable Diffusion, and Midjourney are able to generate highly realistic and detailed images from text descriptions, demonstrating a level of creativity and imagination that was once thought to be exclusively human.\\n\\nHumans seem fundamentally wired to continuously advance technology and improve our knowledge and capabilities. Also, the human brain tends to think linearly, causing us to underestimate the exponential progress of technology. Companies and nations are incentivized by market forces and geopolitical game theory to pursue better intelligence through the advancement of AI.\\n\\nThe Future of Life Institute recently published Pause Giant AI Experiments: An Open Letter. The letter — with notable signatories including Elon Musk, Steve Wozniak and Andrew Yang — caused a stir, calling for a 6 month pause on advanced AI development:\\n\\n“Therefore, we call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium.”\\n\\nMuch of the media and public discourse in response to this letter has focused on who signed it and pushing back on the notion that humanity faces an imminent existential threat of artificial superintelligence. Dystopian claims of runaway artificial intelligence seem hyperbolic to many people, and calling for a 6 month moratorium is not realistic. Good luck convincing China to “pause” their efforts in the AI arms race.\\n\\nBut are there no boundaries? Should we proceed with no guidelines?\\n\\nFor example …\\n\\nAre we comfortable outsourcing decisions to black box AI systems that lack transparency and explainability, making it impossible for humans to understand the reasoning behind decisions?\\nShould we be worried about the development of AI-powered autonomous weapons that make decisions about the use of lethal force without human input?\\nShould we be worried about the potential for malicious actors to use AI for nefarious purposes, such as sophisticated propaganda campaigns?\\nAre our current laws, regulations and political systems equipped to handle the rapid influx of new AI alignment questions that society will grapple with in the very near future?\\nAs AI becomes more advanced, it may become difficult to understand, which could lead to unintended outcomes. AI systems can behave in ways that are unforeseen and difficult to control. The AI alignment problem is a societal challenge that requires collaboration between researchers, engineers, entrepreneurs, policymakers, and the public. It will also require international cooperation between governments and the private sector. This is not just a technical challenge, but also a philosophical and ethical one.\\n\\nThe open letter mentioned above goes on to recommend:\\n\\n“AI research and development should be refocused on making today’s powerful, state-of-the-art systems more accurate, safe, interpretable, transparent, robust, aligned, trustworthy, and loyal.”\\n\\nThis is certainly a worthy goal, and it can be achieved by doing AI in the open. What we currently lack is a framework. Society needs a set of procedures and protocols to make the recommendation from The Future of Life Institute actionable.\\n\\nJointly, we must consider and debate the pros and cons of many ideas, including but not limited to:\\n\\nMandatory disclosure of model details, including training datasets, evaluation methodologies, and known biases\\nDevelopment of a framework that establishes model monitoring and audit requirements for advanced AI systems\\nImplementation of laws that impose liability for AI-caused harm\\nEstablishment of a regulatory authority for oversight and tracking of highly capable AI systems\\nThe first step in achieving a productive framework for safe AI development is an open dialogue among the many stakeholders involved, which includes everyone. We must rise above the hyper-politicized discourse that our dishonest and broken media often forces upon us. This topic is too important and the ramifications are too profound. Join me in advocating for an intelligent and respectful conversation on AI — one that solicits input and open debate from a diverse set of voices to help ensure a path forward that is in our collective best interest.', 'category': 'creative_writing'}\n",
      "### Instruction:\n",
      "Use the Input below to create an instruction, which could have been used to generate the Input using an LLM.\n",
      "\n",
      "### Input:\n",
      "The AI arms race is heating up, and breakthroughs are happening at an accelerating pace.\n",
      "\n",
      "The release of ChatGPT by OpenAI represents a profound leap forward in how humans interface with machines, showcasing the startling progress in large language models. Meanwhile generative AI capabilities such as Dall-E, Stable Diffusion, and Midjourney are able to generate highly realistic and detailed images from text descriptions, demonstrating a level of creativity and imagination that was once thought to be exclusively human.\n",
      "\n",
      "Humans seem fundamentally wired to continuously advance technology and improve our knowledge and capabilities. Also, the human brain tends to think linearly, causing us to underestimate the exponential progress of technology. Companies and nations are incentivized by market forces and geopolitical game theory to pursue better intelligence through the advancement of AI.\n",
      "\n",
      "The Future of Life Institute recently published Pause Giant AI Experiments: An Open Letter. The letter — with notable signatories including Elon Musk, Steve Wozniak and Andrew Yang — caused a stir, calling for a 6 month pause on advanced AI development:\n",
      "\n",
      "“Therefore, we call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium.”\n",
      "\n",
      "Much of the media and public discourse in response to this letter has focused on who signed it and pushing back on the notion that humanity faces an imminent existential threat of artificial superintelligence. Dystopian claims of runaway artificial intelligence seem hyperbolic to many people, and calling for a 6 month moratorium is not realistic. Good luck convincing China to “pause” their efforts in the AI arms race.\n",
      "\n",
      "But are there no boundaries? Should we proceed with no guidelines?\n",
      "\n",
      "For example …\n",
      "\n",
      "Are we comfortable outsourcing decisions to black box AI systems that lack transparency and explainability, making it impossible for humans to understand the reasoning behind decisions?\n",
      "Should we be worried about the development of AI-powered autonomous weapons that make decisions about the use of lethal force without human input?\n",
      "Should we be worried about the potential for malicious actors to use AI for nefarious purposes, such as sophisticated propaganda campaigns?\n",
      "Are our current laws, regulations and political systems equipped to handle the rapid influx of new AI alignment questions that society will grapple with in the very near future?\n",
      "As AI becomes more advanced, it may become difficult to understand, which could lead to unintended outcomes. AI systems can behave in ways that are unforeseen and difficult to control. The AI alignment problem is a societal challenge that requires collaboration between researchers, engineers, entrepreneurs, policymakers, and the public. It will also require international cooperation between governments and the private sector. This is not just a technical challenge, but also a philosophical and ethical one.\n",
      "\n",
      "The open letter mentioned above goes on to recommend:\n",
      "\n",
      "“AI research and development should be refocused on making today’s powerful, state-of-the-art systems more accurate, safe, interpretable, transparent, robust, aligned, trustworthy, and loyal.”\n",
      "\n",
      "This is certainly a worthy goal, and it can be achieved by doing AI in the open. What we currently lack is a framework. Society needs a set of procedures and protocols to make the recommendation from The Future of Life Institute actionable.\n",
      "\n",
      "Jointly, we must consider and debate the pros and cons of many ideas, including but not limited to:\n",
      "\n",
      "Mandatory disclosure of model details, including training datasets, evaluation methodologies, and known biases\n",
      "Development of a framework that establishes model monitoring and audit requirements for advanced AI systems\n",
      "Implementation of laws that impose liability for AI-caused harm\n",
      "Establishment of a regulatory authority for oversight and tracking of highly capable AI systems\n",
      "The first step in achieving a productive framework for safe AI development is an open dialogue among the many stakeholders involved, which includes everyone. We must rise above the hyper-politicized discourse that our dishonest and broken media often forces upon us. This topic is too important and the ramifications are too profound. Join me in advocating for an intelligent and respectful conversation on AI — one that solicits input and open debate from a diverse set of voices to help ensure a path forward that is in our collective best interest.\n",
      "\n",
      "### Response:\n",
      "Write a paragraph about AI governance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "sample_idx = randrange(len(dataset))\n",
    "print(dataset[sample_idx])\n",
    "print(format_instructions(dataset[sample_idx]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction-tune Llama 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up training we want Flash Attention, which needs NVIDIA Ampere GPUs (and that's why we got ourself a g5.2xlarge EC2 instance, which has a NVIDIA A10). \n",
    "\n",
    "First, confirm that we have the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/ec2-user/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 381, in get_device_capability\n",
      "    prop = get_device_properties(device)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 395, in get_device_properties\n",
      "    _lazy_init()  # will define _get_device_properties\n",
      "    ^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The driver is missing. I should have used an AMI with this prepackaged...\n",
    "But let's try install it following the instructions here: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/install-nvidia-driver.html (Spoiler alert: this doesn't give you everything CUDA).\n",
    "\n",
    "If you need to use a password for `ec2-user`, first change to root with `$ sudo su`, then `sudo passwd ec2-user` and type in a new password twice. After password is created, switch back to `ec2-user` by `$ su ec2-user`.\n",
    "\n",
    "For downloading the driver installer from AWS (located in an S3), attach an IAM role with S3 access rights to the EC2.\n",
    "\n",
    "After installation, checking the driver and GPU details should show this:\n",
    "\n",
    "```bash\n",
    "$ nvidia-smi -q | head\n",
    "\n",
    "==============NVSMI LOG==============\n",
    "\n",
    "Timestamp                                 : Mon Jul 31 14:13:24 2023\n",
    "Driver Version                            : 535.54.03\n",
    "CUDA Version                              : 12.2\n",
    "\n",
    "Attached GPUs                             : 1\n",
    "GPU 00000000:00:1E.0\n",
    "    Product Name                          : NVIDIA A10G\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the GPU check passed with no complaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import torch; assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing `ninja packaging` also worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/miniconda3/lib/python3.11/site-packages (23.0)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ninja packaging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But installing `Flash Attention` still failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!MAX_JOBS=4 pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the driver didn't come with `nvcc`. I needed to expicitly install `cuda` with `conda`. (Spoiler alert: the default newest version didn't work!)\n",
    "\n",
    "https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\n",
    "\n",
    "```bash\n",
    "$ conda install cuda -c nvidia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!MAX_JOBS=4 pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I got this.\n",
    "```bash\n",
    "The detected CUDA version (12.2) mismatches the version that was used to compile\n",
    "      PyTorch (11.7). Please make sure to use the same CUDA versions.\n",
    "```\n",
    "So let me try install CUDA pytorch 11.7\n",
    "\n",
    "```bash\n",
    "# uninstall the current CUDA 12.2 \n",
    "$ conda remove cuda\n",
    "# install 11.7\n",
    "$ conda install cuda -c nvidia/label/cuda-11.7.0\n",
    "```\n",
    "\n",
    "After this, I still needed to install `typing-extensions`:\n",
    "\n",
    "```bash\n",
    "$ pip install typing-extensions\n",
    "```\n",
    "\n",
    "Then it finally started to build \n",
    "```bash\n",
    "Building wheels for collected packages: flash-attn\n",
    "  Building wheel for flash-attn (setup.py) ... \\\n",
    "```\n",
    "\n",
    "This took a very long time. But it succeeded the end:\n",
    "\n",
    "```bash\n",
    "Building wheels for collected packages: flash-attn\n",
    "  Building wheel for flash-attn (setup.py) ... done\n",
    "  Created wheel for flash-attn: filename=flash_attn-2.0.2-cp311-cp311-linux_x86_64.whl size=59345049 sha256=b36680a8becd4d33cd6d89a066357a904474c4e63c6f6be322bfd67e808e87b1\n",
    "  Stored in directory: /tmp/pip-ephem-wheel-cache-r2b8rdz7/wheels/6d/b2/9f/b63c6c7f984571c7c8cb2ee8a069461bd355d9265d098dce26\n",
    "Successfully built flash-attn\n",
    "Installing collected packages: einops, flash-attn\n",
    "Successfully installed einops-0.6.1 flash-attn-2.0.2\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction-tune!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to fine-tune Llama 2!. First get the [llama_patch.py](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/utils/llama_patch.py) from Huggingface. Save it in `utils` folder next to the notebook so it can be imported.\n",
    "\n",
    "Now, it's time to instruction tune Llama-2 7B!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up everything and get the model.\n",
    "\n",
    "Needed to install Scipy:\n",
    "\n",
    "```bash\n",
    "$ conda install scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:36<00:00, 48.38s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# use Flash Attention if possible\n",
    "use_flash_attention = False\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    from utils.llama_patch import replace_attn_with_flash_attn\n",
    "    print(\"Using flash attention\")\n",
    "    replace_attn_with_flash_attn()\n",
    "    use_flash_attention = True\n",
    "\n",
    "# Hugging Face model id\n",
    "model_id = \"NousResearch/Llama-2-7b-hf\" # non-gated\n",
    "# model_id = \"meta-llama/Llama-2-7b-hf\" # gated\n",
    "\n",
    "# BitsAndBytesConfig int-4 config 4-bit quantization \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, use_cache=False, device_map=\"auto\")\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Validate that the model is using flash attention, by comparing doc strings\n",
    "if use_flash_attention:\n",
    "    from utils.llama_patch import forward\n",
    "    assert model.model.layers[0].self_attn.forward.__doc__ == forward.__doc__, \"Model is not using flash attention\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the config for PEFT and prepare the model for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "# LoRA config based on QLoRA paper\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters for trianing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"llama2-7-int4-dolly\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_eval_batch_size=6 if use_flash_attention else 4,\n",
    "    # per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=10,\n",
    "    logging_strategy=\"epoch\", # log each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    disable_tqdm=True # disable progress bar since packing makes the number incorrect\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `SFTTrainer` to start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47969937/reconnecting-remote-jupyter-notebook-and-get-current-cell-output\n",
    "# a workaround for HuggingFace progress table updates. Just configure a callback log_callback = PrinterCallback(), trainer.add_callback(log_callback), set logging_strategy='epoch' in the TrainingArguments, and copy the implementation of PrinterCallback() from this example. And thanks to @Mercury's solution, the output will be redirected to the nb.log file\n",
    "\n",
    "# redirect HuggingFace logs to our log file\n",
    "\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            print(logs)\n",
    "\n",
    "log_callback = PrinterCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "# max_seq_length = 2048 \n",
    "max_seq_length = 1024 # reduce max sequence length because of CUDA out of memory error\n",
    "# max_seq_length = 512 # reduce max sequence length because of CUDA out of memory error\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=format_instructions,\n",
    "    args=args\n",
    ")\n",
    "\n",
    "# add log callback defined above\n",
    "trainer.add_callback(log_callback)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training at: 2023-08-01 05:51:44.596799\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"Start training at: {datetime.datetime.now()}\")\n",
    "\n",
    "trainer.train() # there won't be a progress bar\n",
    "\n",
    "print(f\"Finished training and start saving at: {datetime.datetime.now()}\")\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "print(f\"Finished saving at: {datetime.datetime.now()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time it gave me an error: `'AcceleratorState' object has no attribute 'distributed_type'`. Upgrading `accelerate` solved the problem (Kernel restart needed).\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/huggingface/accelerate\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA out of memorry error\n",
    "\n",
    "The second time it gave me CUDA out of memory error\n",
    "\n",
    "```\n",
    "OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB (GPU 0; 21.99 GiB total capacity; 17.27 GiB already allocated; 1.78 GiB free; 19.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "```\n",
    "\n",
    "To resolve it I halved SFTTrainer's max sequence length `max_seq_length` from 2048 to 1024, and set the batch size `per_device_eval_batch_size` to 4. Finally the training begun.\n",
    "\n",
    "https://stackoverflow.com/questions/15197286/how-can-i-flush-gpu-memory-using-cuda-physical-reset-is-unavailable\n",
    "\n",
    "To release unreferenced memories:\n",
    "\n",
    "```python\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "If everything fails and you want to kill all nvidia processes eating GPU memory, try this:\n",
    "\n",
    "```bash\n",
    "$ nvidia-smi\n",
    "```\n",
    "This will show all the processes.\n",
    "\n",
    "```\n",
    "Tue Aug  1 05:44:18 2023\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
    "|  0%   39C    P0              59W / 300W |      4MiB / 23028MiB |      4%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|  No running processes found                                                           |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "Kill each of them by PID, e.g.:\n",
    "\n",
    "```bash\n",
    "$ sudo kill -9 47676\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_flash_attention:\n",
    "    # unpatch flash attention\n",
    "    from utils.llama_patch import unplace_flash_attn_with_attn\n",
    "    unplace_flash_attn_with_attn()\n",
    "\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "args.output_dir = \"llama-7-int4-dolly\"\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    args.output_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
